% Encoding: UTF-8

@Article{Mendonca2025,
  author         = {Mendonça, Pedro C. and Quintal, Filipe and Mendonça, Fábio},
  date           = {2025},
  journaltitle   = {Applied Sciences},
  title          = {Evaluating LLMs for Automated Scoring in Formative Assessments},
  doi            = {10.3390/app15052787},
  issn           = {2076-3417},
  number         = {5},
  url            = {https://www.mdpi.com/2076-3417/15/5/2787},
  urldate        = {2025-11-30},
  volume         = {15},
  abstract       = {The increasing complexity and scale of modern education have revealed the shortcomings of traditional grading methods in providing consistent and scalable assessments. Advancements in artificial intelligence have positioned Large Language Models (LLMs) as robust solutions for automating grading tasks. This study systematically compared the grading performance of an open-source LLM (LLaMA 3.2) and a premium LLM (OpenAI GPT-4o) against human evaluators across diverse question types in the context of a computer programming subject. Using detailed rubrics, the study assessed the alignment between LLM-generated and human-assigned grades. Results revealed that while both LLMs align closely with human grading, equivalence testing demonstrated that the premium LLM achieves statistically and practically similar grading patterns, particularly for code-based questions, suggesting its potential as a reliable tool for educational assessments. These findings underscore the ability of LLMs to enhance grading consistency, reduce educator workload, and address scalability challenges in programming-focused assessments.},
  article-number = {2787},
  file           = {:Evaluating LLMs for Automated Scoring in Formative Assessments.pdf:PDF},
  priority       = {prio1},
}

@Article{Kasneci2023,
  author       = {Enkelejda Kasneci and Kathrin Sessler and Stefan Küchemann and Maria Bannert and Daryna Dementieva and Frank Fischer and Urs Gasser and Georg Groh and Stephan Günnemann and Eyke Hüllermeier and Stephan Krusche and Gitta Kutyniok and Tilman Michaeli and Claudia Nerdel and Jürgen Pfeffer and Oleksandra Poquet and Michael Sailer and Albrecht Schmidt and Tina Seidel and Matthias Stadler and Jochen Weller and Jochen Kuhn and Gjergji Kasneci},
  date         = {2023},
  journaltitle = {Learning and Individual Differences},
  title        = {ChatGPT for good? On opportunities and challenges of large language models for education},
  doi          = {https://doi.org/10.1016/j.lindif.2023.102274},
  issn         = {1041-6080},
  pages        = {102274},
  url          = {https://www.sciencedirect.com/science/article/pii/S1041608023000195},
  urldate      = {2025-11-30},
  volume       = {103},
  abstract     = {Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This commentary presents the potential benefits and challenges of educational applications of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.},
  file         = {:ChatGPT-for-good-On-opportunities-and-challenges-of-large-language-models-for-education.pdf:PDF},
  keywords     = {Large language models, Artificial intelligence, Education, Educational technologies},
  priority     = {prio1},
}

@Article{Ye2023,
  author   = {Hongbin Ye and Tong Liu and Aijia Zhang and Wei Hua and Weiqiang Jia},
  date     = {2023-09-13},
  title    = {Cognitive Mirage: A Review of Hallucinations in Large Language Models},
  doi      = {https://doi.org/10.48550/arXiv.2309.06794},
  url      = {https://arxiv.org/abs/2309.06794},
  urldate  = {2025-11-30},
  file     = {:C\:/Users/milan/Downloads/Cognitive Mirage A Review of Hallucinations in Large Language Models.pdf:PDF},
  priority = {prio1},
}

@Comment{jabref-meta: databaseType:biblatex;}
